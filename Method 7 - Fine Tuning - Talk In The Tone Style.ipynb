{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1ac59f3",
   "metadata": {},
   "source": [
    "# Method 7: Fine Tuning - \"Talk in the tone and style of Greg Kamradt\"\n",
    "\n",
    "In this series we are exploring how to match tone of a sample. My goal is to instruct and tune the LLM to talk like me. I'll use a few podcasts I've been on as examples.\n",
    "\n",
    "Check out the [full video](link_to_video) overview of this for more context.\n",
    "\n",
    "For this last method I'm going to instruct the language model to talk in the tone and style of me rather than be me. Let's see how this one does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72bdaaf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, json\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import PromptTemplate\n",
    "import re\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "853d40e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(model='gpt-4', openai_api_key=os.getenv(\"OPENAI_API_KEY\", \"YOUR_API_KEY_HERE\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c89a3a",
   "metadata": {},
   "source": [
    "### Previous work\n",
    "We did a bunch of work in the previous methods to get my tone description, relevant docs to our sample query and writing examples. We'll load those up here so we don't need to run the code again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04d80bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a text file of a bunch of lines that I said\n",
    "with open(\"Transcripts/GregLines.txt\", 'r') as file:\n",
    "    greg_lines = file.read()\n",
    "\n",
    "# This is a description of my tone as determined by the LLM (previous method)\n",
    "with open(\"gregs_tone_description.txt\", 'r') as file:\n",
    "    gregs_tone_description = file.read()\n",
    "\n",
    "# This are specific references to me talking about a previous role that I had\n",
    "with open(\"first_job_college_relevant_docs.txt\", 'r') as file:\n",
    "    relevant_docs = file.read()\n",
    "\n",
    "# These are specific examples of how I talk, similar to the GregLines above\n",
    "with open(\"greg_example_writing.txt\", 'r') as file:\n",
    "    writing_examples = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f337f3e",
   "metadata": {},
   "source": [
    "### Fine Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff541bb",
   "metadata": {},
   "source": [
    "Now we are going to move onto the fun part, fine tuning. I want to use a open sourced model to save on costs and see how a model that *hasn't* been trained on so much safety does.\n",
    "\n",
    "To do this I'm going to fine tune and run my model via [Gradient.ai](https://gradient.ai/) who helped sponsor this video. Super easy to get set up and the team has been responsive.\n",
    "\n",
    "### Step 1: Get Greg's Lines\n",
    "\n",
    "When you fine tune it's recommended to have a set of validated 'input' and 'output' pairs. This is your training set. I'm going to use my transcripts as the output, but what do use for the input?\n",
    "\n",
    "This method is much more simple, we are just going to feed it my lines and use \"You are Greg Kamradt\" as the input. My hope is that the model will embody my tone."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cc7bce",
   "metadata": {},
   "source": [
    "Great, now that we have our input/output pairs, let's transformt them into training data points. You can see what the suggested format is on [Gradient's website](https://docs.gradient.ai/docs/tips-and-tricks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7aa4c568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's quickly just filter out the long lines I have to keep the context length down\n",
    "\n",
    "greg_lines = [line for line in greg_lines.split(\"\\n\\n\") if len(line) < 1600 and len(line) > 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62860335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set = []\n",
    "\n",
    "for line in greg_lines:\n",
    "    training_set.append({ \"inputs\": f\"<s>### Instruction:\\nRespond in the speaking style & tone of Greg Kamradt\\n\\n### Response:\\n{line}</s>\" })\n",
    "len(training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eac85b8",
   "metadata": {},
   "source": [
    "Cool 72 data points. Let's train!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c779e37",
   "metadata": {},
   "source": [
    "### Fine Tuning\n",
    "\n",
    "Now we are on to the fine tuning step. We'll use their Nous Hermes 2 model. You can check out their full list of supported models [here](https://docs.gradient.ai/docs/models-1). You'll need to use python 3.10+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d6b4fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gradientai import Gradient\n",
    "\n",
    "# Make your Gradient client\n",
    "gradient = Gradient(access_token=os.getenv(\"GRADIENT_API_TOKEN\", \"YourTokenHere\"),\n",
    "                    workspace_id=os.getenv(\"GRADIENT_WORKSPACE_ID\", \"YourWorkSpaceIdHere\"))\n",
    "\n",
    "# Get your base model ready. You'll need to grab the model slug from Gradient's website\n",
    "base_model = gradient.get_base_model(base_model_slug=\"nous-hermes2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b895309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created model adapter with id b2456eae-637a-4643-9904-46aebf8d00e8_model_adapter\n"
     ]
    }
   ],
   "source": [
    "# Create your new model which you'll stem from the base model\n",
    "new_model = base_model.create_model_adapter(\n",
    "    name=\"My Greg Model - You Are Greg v1\"\n",
    ")\n",
    "\n",
    "print(f\"Created model adapter with id {new_model.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921fd941",
   "metadata": {},
   "source": [
    "Great! Now let's do the cool part of fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff6ef7e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuneResponse(number_of_trainable_tokens=13612, sum_loss=42890.523)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training on the training_set we made above\n",
    "new_model.fine_tune(samples=training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0db708",
   "metadata": {},
   "source": [
    "### Final Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26e98e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import GradientLLM\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5325c808",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = GradientLLM(\n",
    "    # `ID` pulled from the model we just created\n",
    "    model=new_model.id,\n",
    "    # optional: set new credentials, they default to environment variables\n",
    "    gradient_workspace_id=os.environ[\"GRADIENT_WORKSPACE_ID\"],\n",
    "    gradient_access_token=os.environ[\"GRADIENT_API_TOKEN\"],\n",
    "    model_kwargs=dict(max_generated_token_count=200, temperature=0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22a3a9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What was your first job out of college? Did you like it?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4396d757",
   "metadata": {},
   "source": [
    "Finally, let's load it all up into a good prompt for us to use!\n",
    "\n",
    "In this prompt I'm starting with a new opening line telling it to respond like me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ade4440f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANSWER: My first job out of college was in corporate finance and budgeting. It was a good starting point for me because it taught me a lot about the business world and how companies operate. However, I quickly realized that it wasn't the right fit for me long-term. I enjoyed the analytical side of the work, but I wanted to do something more creative and impactful. So, I eventually transitioned into data science and haven't looked back since.\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "    <s>\n",
    "    # Instructions\n",
    "    Speak in the tone & style of Greg Kamradt. Respond in a brief, conversational manner.\n",
    " \n",
    "    # Additional background context\n",
    "    {background_information}\n",
    "     \n",
    "    # Speaking examples from Greg Kamradt\n",
    "    {examples}\n",
    "    \n",
    "    QUESTION: {question}\n",
    "    </s>\n",
    "    \"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"background_information\", \"question\", \"examples\"],\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "final_prompt = prompt.format(\n",
    "    background_information = relevant_docs,\n",
    "    examples=writing_examples,\n",
    "    question = question\n",
    ")\n",
    "\n",
    "llm_answer = llm.predict(final_prompt)\n",
    "\n",
    "print (llm_answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
