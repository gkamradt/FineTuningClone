00:00:00 Greg: Amazing thing about what's happening with AI is it's text in, text out. And a 5 year old can put text in, a seasoned software developer can put text in, or your grandmother could put in text. With regards to open source, yes, open source is tough to compete with because there's the collective, intelligence of humanity on those.

00:00:17 Saurabh: Yes. However Right. Right.

00:00:19 Greg: The benchmarks all show that open source aren't as good as the closed models. I'm a capitalist at heart, and so I love market pressure. And so I love the fact that there are multiple model providers all battling for consumer value and consumer attention. Because as a consumer myself, I will gladly, love the benefit of them battling for my

00:00:39 Saurabh: own business. Hello, and This is Saurabh Pathak. And today's podcast, our guest is mister Greg Kamwer. Greg published AI tutorials on his YouTube channel, Data independent, which has got almost 30,000 subscribers. In today's video, we are going to discuss with Greg in detail on land chain, its use case in third world countries, and the future it holds. So let's get started. Hello, Greg. How are you, Will? Thank you for giving us your time and joining us Anur brought us today. It's been a beautiful evening in India. I hope, it's been the scene at your place. So could you just let us know a bit about yourself?

00:01:25 Greg: Yes. Absolutely. Well, I tell you what. 1st of all, thank you very much for having me for the for the conversation today. My name is Greg Kamrad, and my background is actually in b two b products. So I'm an ex Salesforce person, and I worked out on the growth team at Salesforce. And I led growth for sales and service cloud. And then after that, I was the 1st business hire at Digits, which was a Fintech Series C company. And I was the 1st, operations hire. So, basically, anything that involved spreadsheet, and the business was up to me. However, this year, I've been knee deep in helping others learn how to build AI applications mainly with the Langchain library.

00:02:01 Saurabh: At at some Museum Portfolio app, you've been working with a lot of things in your in a car in the companies. Okay? So what actually noted motivated you to come to AI to start your channel and start publishing the videos?

00:02:15 Greg: Yeah. So my Preference as a creator is about connecting the content and teaching others how to build impactful tools. Because in my history with my career so far, The most satisfaction that I've gotten and the most efficiency that I've gained has been building my own tools. So whether it's, building a lead score, whether it's building a small automation script, whether it's something in Excel or whatever it may be. So when I saw that AI was coming around, I saw a lot of opportunity to build some really cool tools that would impact me. However, I wanted to teach others how to build those tools for themselves and so they could have the impact. And I found that the best way to do that was through creating tutorial content and getting people started from the ground up.

00:02:55 Saurabh: That's amazing. Good to know about that as well. So before proceeding, I want to let our listener know that, Greg has got a YouTube channel by the name Data Independent that has got almost 24,000 subscribers. Do visit that channel. It has got an amazing to do a video. I am pretty sure that you will like it because I definitely like those videos and Started working on language mode, so I've watched those videos. That's really amazing. Right? So, Greg, this AI thing, we know that it's not something very new in the market. Right. It's been there for the past 10 years. A lot of companies have been working on that. Okay. But if I talk about that once this chat GPD game, like, after 1 like, in the past 1 year, A lot of those has been created, a lot of landless models are, like, you know, developing and people are using it. So what actually triggered this thing? Because people have I've been using that, like, doing experiments on AI for past 10 years in different different companies. But the buzz that's leading right now, what actually happened after Chargegity?

00:03:53 Greg: Well, I think the reason why there's so much buzz now is because for any new technology to get adequately adequately adopted, you need the story along with it. And the amazing thing about what's happening with AI is it's text in, text out. And a 5 year old can put text in, a seasoned software developer can put text in, or your grandmother could put in text. And so the just the the generalized nature of ChatGPT in in the 1st place, I think, was massive for the adoption. Right? Now if we take a look back, ChatGPT came out at the end of October, early November 2022. And Yes. At the beginning, people were just making poems about their cats. You know? They were trying to figure out, like, Christmas presents should to go and get people. I think that the really, really cool stuff started to happen once people understood that, no, you can actually use language models not only for text generation, but also as a reasoning engine, as a classification engine. And it has really, really wide general capabilities, which is has been really cool to see the, see how the community has been developing on it on top of it.

00:05:01 Saurabh: Could you let our listener know, A bit in a simple language, and what actually is a language model? So basically, our audience are are from, you know, newbies to fresher. So if, we want to tell them in a very simple language and, like, this they can understand, what actually is a large language model?

00:05:18 Greg: Absolutely. So The in extremely simple language, think of a large language model as a really good predictor of the next word. Right? And so if it is the day that you were born, and I come to you and I say, happy, you know that I'm likely gonna say birthday coming up next. Right? A language model is the same exact thing, and it is gonna predict the next word. Now what has been really, really awesome is the emergent behavior that comes from that from those capabilities. So just because you're predicting the next word, you might first think, well, how smart could it actually be? Right? What's really cool is you can ask these language models to generate you a poem. You can ask it to read a financial statement. You can ask it to answer a question about a piece of text. Right? You can also ask a language model. Hey. I have 2 routes that I could take. Should I go left or should I go right? And it will actually intelligently understand your situation and suggest a route to take. And a really big topic that we're seeing these language models take on right now is the concept of agents. And you can think of agents as an autonomous decision maker. So just from the emergent behavior predicting the next word, we get smart agents that are capable of thinking and going through it.

00:06:35 Saurabh: Okay. Okay. That's really a pretty cool definition. I hope all users must have to understand, what actually Actually, a language model is in a very basic terms kind of like a predictor. Okay? And, obviously, you can do a lot of cool stuff using the language model. You know, there were, we talk of AI. I remember watching an episode on HBO. There was an episode before of targeting Silicon Valley. Okay. Mhmm. There are bunch of friends who are trying to make a decent drive network. Okay? And there comes a stage, okay, in that series that, this network goes out of hand And the main character he does that AI is like a is like a black box. Right? You don't actually know what actually happened. You can't even clear it out. Right? So many people are very scared that this AI technology, if they get in the wrong hands or if you get implemented in a, like a wrong way, It could have pretty worse scenario as well. Right? So what can we talk on that as well?

00:07:29 Greg: Yeah. I see AI just as another technology that's coming through. So you could say the same thing about the Internet. You could say the same thing about electricity. If bad actors got ahold of this technology, then they're gonna do it. They're gonna do something wrong with it. Right? I believe that, Yes. There is the ability for bad actors to cause to do things with AI that, may not be beneficial to the rest of the world. But with that pressure with that pressure comes the other side of the coin too. There are a lot of people who want to do good with AI. So, yes, the bad actors will get their capabilities, uplifted, but also the good folks and law enforcement and governments will also have AI that they can battle back and push with on those. So I don't see it as a one-sided sword here. It's gonna be double sided. And I personally am not am not worried about it. And I think that one of the biggest things that you can do to to develop advancement is to have a large incentive. Now usually incentive can come through those forms of, monetary incentive or societal pressure from it. Now when you have such negative consequences on the brink and it could actually happen, then, that's pretty good incentive to come up with good AI alignment and make sure that it's working out okay.

00:08:45 Saurabh: Yeah. Sure. You see, like, this also has a good side and a bad side. Right? And, you know, like, since A lot of AI tools are coming, so every company is trying to make best use of each and every AI tool. Right? I read an article, 2 days back About, there was an issue, like, a lot of AI extensions have been developed on the Chrome, but some of those extensions are actually acting as a malware, which are collecting data, data on the user. So when we talk about developing an AI application and using it, Are there any legal point of view, legal side of that as well? That's the number 1 question. Second question is that before making use of any AI application, Okay. In terms of company or enterprise, should they, invest, first on that, doing some R and D that what actually that AI tool is doing, What actually is collecting? And once they have, they are sure that it's perfectly fine, they can pass on to their employees to make use of that.

00:09:44 Greg: Yeah. I mean, it's a good question, and I would treat it like any other technology. So before your company allows you to install a Chrome extension, you wanna know what that Chrome extension is doing in the 1st place. Now there's a few layers of this because Chrome itself as a developer store, they need some basic level protection for their consumers on top of their app. They don't want Chrome to be known as the spam place where all the extensions are not providing value. So I think Google has a level of responsibility. Well, I shouldn't say they have responsibility. They have an incentive to make sure that Chrome extensions are healthy for their platform. Right? The 2nd piece is just even before AI. Take AI out of the question. If you're a Fortune 500 company, before you let your employees install a Chrome extension, You're gonna do background checks on what actually this Chrome extension is doing. So you're gonna look at the code, and you're gonna look at the other third party tools that that extension is using. Now the interesting part about language models is that the intelligence is consolidated to a few main players. For the most part, you can run your own open source models, but most of these folks are gonna be using chat GBT. They're gonna be using Bard and Palm from Google and Anthropic and, and all these other model providers. So when you look at these Chrome extensions, it's important to know where your data is going and the, compliance practices of all the third party tools that that Chrome extension's actually using. So if you're if you're worried about OpenAI, they have their data privacy issues you can go check out online.

00:11:06 Saurabh: Yes. Yes. Right. Right. Definitely. And do these, AI companies, they also, like, follow the judica revolution as well? Because in Europe, it's it's pretty completely for, for to to, like, you know, sign for GDPR. Okay? That, whenever you are asking the data from the user, you need to get a consent. And whenever a user wants to, like, delete that, all the data, you should get it deleted. And a lot of companies haven't find in the past of that, even Facebook and Microsoft. So do these AI application days sign for GDPR policy as well if if they release it in a certain continent?

00:11:39 Greg: Yeah. You know, you would hope that they're following the regulations of the localized country that they're choosing to deploy in. However, the reality of it is is all these companies are taking calculated risks for how they wanna proceed and move forward with it. So if they choose not to get consent from the user because they wanna go faster, that's their choice. However, they are gonna be breaking the law in some countries. And as long as they're okay with that risk, they will still continue to do it. The old saying move fast and break things, I know it's gotten a little bit of slack over the past couple years. I don't necessarily endorse it, but I do know a lot of companies that will choose to move fast and try to find product could fit first before they worry about legal legal regulations and compliance.

00:12:22 Saurabh: Yeah. Yeah. Definitely. You know, there's one more interesting question that, a lot of tech company who are working on LMS, they have it, that better to make use of open source or a proprietary LMS. You know, like, last month, they bought a leak in Google. There's a news that, they have been reported, Google, that they Cannot compete with the open source technology once they come onto the ecosystem. Right? You might have heard of that. So what's your thought on using any potentials element or a Go for it. Yeah. And then, like, open it.

00:12:51 Greg: Yeah. You know, it it's it's always a balance. Of course. I mean, every every business has different priorities for it. For the types of developments that I do right now, I'm not worried about handing over sensitive data, and I'm worried about cost, latency and intelligence. And in fact, if I were to prioritize those intelligence, latency, and then cost. So I want something that's really smart, really fast, and then eventually that it's cheap. I don't for my types of developments right now, I'm not worried about sensitive data. I'm worried about building really impactful products and making sure that value is there. Now with regards to open source, yes, open source is tough to compete with because there's the collective, intelligence of humanity on those. Yes. However

00:13:32 Saurabh: Right. Right.

00:13:34 Greg: The benchmarks all show that open source aren't as good as the closed models. And so I was just Interviewing Siki Chen the other day. He's the co he's the founder and CEO of, Runway. He said that he believes that Open source models will always be about 18 months behind closed source models. So will we ever see an open source model that's as good as GPT 4? Absolutely. 100%. It's just a technology problem. Time solves technology problems. Well, innovation solves technology problems.

00:14:02 Saurabh: Yes.

00:14:02 Greg: However, in that 18 months when when those open source models are getting better, OpenAI is gonna improve their capabilities. They're gonna come out with good stuff, and they're gonna be on a GPT 5, 6, whatever.

00:14:15 Saurabh: Yeah. I guess maybe, you know, like, looking looking in the future, all the time, data privacy is one thing that, right now, users are mostly worried about. Right? In the past, they might not have been, but in today's day, they are surely worried about that. Their data should not be handed to any other third party. Right? So they are very much, you know, concerned about that. Okay? So open source really presents a opportunity that if you don't want Like, hand over the data. You can truly make use of open source, and then start to customize and build your own, which is specific to your own database. Right? And And then you can release it in the market for for the people to make you look for an application. So there's one aspect that it might default To come to the company, there's a company which, has a faster go to market. They might use our proprietary island and try to build application and ship it faster. But But there's a company who want to, like, do it in long term. Okay? They want to build something which people can use. They might go with using the open source and then customize it for something about themselves.

00:15:15 Greg: Yeah. You know, a a few things. Companies are worried about data privacy. Yes. But the minute that you use another third party tool, That third party tool is using other people and other tools to to start off in the 1st place. So, yes, people are worried about data privacy with AI, But I think, honestly, it's a it's a story that is needs to be watched out for right now because it's a new paradigm. But people will become used to giving their data to these model providers just like they got used to giving it to Google, giving to Amazon, giving it to Microsoft. Right? So that that's the that's the 1st piece. The 2nd piece is if you're gonna be developing your own language model in today's date, you know, in June 2023, You'd still need to hire either a cons a consulting firm that knows how to do that or a machine learning engineer internally that's gonna help you manage the pipelines and the training and the deployment and the monitoring. And those people are expensive, and they're heavyweight. And they're really, really good at their jobs, but you need to be able to make sure that you have the capital to invest if you're gonna go down that certain direction. So it's in my personal philosophy as putting on my, my operator and business hat is that you should get Your product's working first. Make sure you have product market fit. Make sure the distribution's working. Make sure your customers are loving it. Your storyline works. Then go and invest in other methods that may give you the more privacy that you want or reduce latency or the fine tuning. So making sure that the model is more customized to your use case. But anything before you do all that is a little premature. And, if you're gonna find out that your product doesn't work, I would hope that you would do it sooner rather than later.

00:16:52 Saurabh: Definitely. You know, even, Sam Edelman has been in India a few years back. He was doing rounds with different CEOs. Okay? So in a conference, 1 night I even asked him that, suppose, if today someone wants to create a language model like a chat g p t. Okay. What's your thought on that? And he just told, it's hopeless. Right? He just told me it's hopeless. Okay. And even, you know, he has been, being very vocal of this fact that today, every company should be AI or should work on AI. Otherwise, you are running a losing cause. Okay. So what's your take on that? What like, should every company just come right now on the AI? Otherwise, they are not they are not going to be Is this not the main feature for them?

00:17:34 Greg: Yeah. It's a good question. 1st, a reaction on the quote that you had mentioned. It is kind of romantic and beautiful that to think how hard it is to come up with an if you were to try to mimic GPT 4 today, it would take a substantial amount of work and people and money to end up doing it. Right? Not only that, it would take a ton of coordination to do it as well. So what's amazing is Why doesn't Google have something that benchmarks as good as GPT 4? Google has all the money in the world. They have more researchers than they know what to do with, but yet they they still haven't done it yet. Or they haven't released it at full scale yet. So OpenAI has done something pretty something pretty special to be able to combine all those boxes and bring it out together. And I really I'm a capitalist at heart, and so I love market pressure. And so I love the fact that that there are multiple model providers all battling for consumer value and consumer attention. Because as a consumer myself, I will gladly Love the benefit of them battling for my own business.

00:18:33 Saurabh: Yes. That's correct. In all these wars going on And between different different language model, it's ultimately the consumer who's enjoying the show. Coming back to a very interesting question from one of the viewers, Is AI going to be the go to solution for every other problem? Or is going to be very specific for a certain use case of problems?

00:18:56 Greg: Yeah. Absolutely. Well, I remember talking earlier around the generality of AI and how good it is as adapting to a lot of different use cases. And it also storytells really well. Oh my god. It's gonna change the world, or, oh my god. It's gonna automate away, you know, x, y, z job. The fact of the matter is is that there are early promises of some really cool things. It's not a it's not a magic wand. It's not gonna do every single thing that you want, for you. And there are a series of things, that it's not good at, explicitly. So one time, a, a a pair of cofounders came to me, And they were running a finance startup. And they asked me, hey, Greg. Can you help us create a intelligent AI model that will do financial forecasting for us. And what they wanted to do was pass in a table of numbers to the language model, have it do some complicated interactions, and then have it pass back a table of numbers. And the fact of the matter is is that's not a task that it's very good at. It's good at some it's good at reasoning abilities. It's good at language task, language digestion. And, so there are gonna be more capabilities in the future that help with those types of things. But the main message I wanna send is it's not a magic wand and it really invests or really pays off to invest in understanding what a language model is good at and what it's not good at.

00:20:13 Saurabh: Yes. Definitely. I can't disagree with you. We discussed a lot on AI and a use case. So here comes a golden question for you, which Is, quite trending, in the past few months on social network that is AI really going to take away the job? Is going to bring a new revolution in the job market.

00:20:39 Greg: Yeah. So one of the questions I ask myself is, what will headcount distribution look like in companies in 5 years? I don't think any department is gonna go away per se, but I think that headcount distribution could change. So the output that a marketing team did with a 100, Maybe just a hypothesis. Maybe you could do the same thing with 75 people, right? Maybe 50 people. I in the interim, what we will see is we'll we will see professions that are augmented by AI. So they help people go faster. Now, really, when you think about jobs reducing, there's 2 pieces of this is, can AI increase the amount of impact and output that the same number of team members have? If so, then. Well, and then the flip side of that is, or do you get the same output, but you want a reduced number of people for it? Now where I'm going with this is let's take salespeople as an example. And you have, let's just say 20 AEs at your company and, they're selling, I'm just gonna make up a round number. They're selling $1,000,000, well, $1,000,000 a month. Right? Let's just use round numbers. With AI, do you expect that $1,000,000 a month to go up? If so, how would that tactically happen? So I think when some people say, oh, we're gonna automate away from a job, we're talking about generalities. They're not talking about specifics. I would love to chat with somebody who thinks that's how it's gonna happen. And then we tactically get down to the nuts and the bolts because is that AI ready to write emails? Are they ready to make human distinction? Are they ready to make judgment calls? Are they ready to insert data into a CRM? There are a lot of things that go into somebody's job in the 1st place. And for that sales example, Sales is a gray area, and there's a lot of colorful creativity that's needed for. So I don't think that any jobs will get replaced today or frankly, even before the end of the year, I would say that we're going to see a transition of roles. So just like how we, how social media marketers, they weren't a thing, you know, I'm gonna call 10 years ago, but in the past 10 years, that's when it started to come around. So there will be some jobs that transitioned. There will be new jobs we'd never even heard of in the 1st place. Like for example, a plug in manager at a Fortune 500 company. I believe that there's gonna be a ton of internal plug ins that LLMs are gonna be talking to, not talking to external data, just internal within the company. And right now the team that would manage that is likely gonna be the ML team, maybe some dev teams, but there's gonna be best practices that somebody needs to pull around and, specialize in, and I wouldn't be surprised if that was a job title in a couple years.

00:23:10 Saurabh: Yes. Very likely said. You see, Yeah. Given a very good example of, like, a sales team. Right? And, working in that, we know that for doing a sale, It's a lot of the human connection that is involved rather the, you know, like, putting on just robotic facts. Right? So you need to get in touch with the person. You need to discuss with them. And you know, like, we are, like, an emotional being. Right? They're not machines. Right? So it plays a lot of role that how you, you know, how you, like, you know, communicate with a person, how you, give them knowledge about the thing that you are selling. And definitely, like, you need to do certain follow ups and then other things involved which which requires a lot of human emotional Ocean. Right? Not not basically a iQ like that. Right?

00:24:01 Greg: Yeah. I think you're absolutely right. And what we're talking about here is we're talking about connection down in the 1st place. Human to human human to human connection on it. There's a reason why people don't like cold emails. It's because it was sent by a bot. It was not personalized. It's not authentic, and there's no connection that comes with it. So I agree with you. And it's interesting because when I was talking to Siki, I I mentioned that interview earlier, he I asked him what motes and differentiators he thought companies were gonna have in the future. And one of them was relationships. And so you there's no substitute for relationships. The relationship that I have with you or with my audience or whoever it may be. That's something that AI cannot pull away from however, smart or intelligent, it may be.

00:24:39 Saurabh: Right. Right. Definitely. So, Greg, walking in this field, if I ask you, like, if you wanna pass on, some message Message to our people. So what would be your 2Â¢ of advice for the for those, for those Undergraduates who are studying college or looking to get into college. Is it the right time for them to get into the ecosystem Oh, first, they need to complete their basic education, and then they can go on building this cool stuff around AI.

00:25:13 Greg: Yes. So I guess 3 things that I would say first and foremost, get your education 100% see it through because your college degree, your college degree Your college degree helps you out on multiple levels. Not only is it the learning that you're doing, it's the credentials that you have, but it's also a signal to the market that you can complete a task. And that task is a long one. Right? It's really your 1st big, huge responsibility with an educational sense, in your life there. Now is that the answer for everyone? No. But advice is grayscale. And I would go as to say that, like, 90%, 95% of people should just finish the college degree. Okay. Now while you're doing that, though, I'm a huge advocate for side projects, and you going and exploring what interests you. And if you're ever wondering about what to work on, literally just follow your interest. Are you excited about it? What do you wanna learn more about? What do you like reading about? Because That interest will translate into energy, will translate into your ability to do projects. Okay? So my 2nd piece of advice is that I would do by learning. I mean, I'm sorry. I would learn by doing. So if you have a topic you wanna learn about, maybe it's AI, go and build a tool using AI that's interesting to you. That tool could be as simple as a prompt on chat g b t. Go get an account, a free account on chat g b t, go plug in some prompts and go have some fun with it. Alright? Now it gets really interesting when you use chat GPT to help you code or to help you build these applications. There's even no code applications if you don't wanna learn how to code. Go and build projects that interest you. Now my 3rd piece of advice is you need to share your projects. A major differentiation point for students and for people who are rising in the industry is sharing their work. So much like we're all creating content here, we're creating it for a reason so that people can know our name, and we can leverage our ability here. So if I go and create 1 YouTube video and it's viewed by a 1000 people, that's this that's that's as if I gave a tutorial lesson 1 on 1 to a 1000 people. Right? And then I can start to form a relationship with them, and then I can start to build up my differentiation point. So it used to be I used to hate when people used to tell me, oh, Greg, you need to build a portfolio because I was in data analysis. And so people said, you know, Greg, you need to have a data analysis portfolio. I didn't like hearing that at all because it's like, why? And what would, what would I do with that portfolio? I'm a big fan of it now, but you need to make sure that the portfolio works for you. So don't just put it up on a website where nobody can see it and you hope people come by it. You need to be engaging on YouTube, engaging on Twitter, engaging on LinkedIn, and actually sharing the work that you wanna do.

00:27:55 Saurabh: Right. Right. Definitely. As for you, what is the importance of community for, in the AI ecosystem? Because in open source, we believe that our community plays a major role for, for, you know, like, adoption of any open source project. So is it same with the AI ecosystem as well? Like, you build a AI tool and you want to get more people involved? So do you also work, so this ecosystem also works on a lot of community feedback as well, just like open source?

00:28:30 Greg: You know, I would say. Let's talk about 2 different personas here. So if you're a big company like open AI, yes, 100%. Because think about all the features that they've come out with. They wouldn't have known how to prioritize their product roadmap unless the open source community was demonstrating their work on the demand about how this, technology should be used in the 1st place. Alright. Now what I mean by that is Sam Alden talks about the collective intelligence. The reason why they release things on a slow basis is because they want to piecemeal their technology to see how the community reacts with it. Because you're gonna get the ethical people. You're gonna get the hackers. You're gonna get the new people. You're gonna get enterprise. You're gonna get fortune 500, all pushing on this technology. And you wanna make sure that you do it in the right way. So I'm a really big fan of open source community. And when I say that, I just mean people building in public and sharing their work. So I'm a really big fan of people doing that and people sharing because that helps our collective intelligence grow in the 1st

00:29:25 Saurabh: That's a very wonderful insight on that, Greg. So, Greg, I think we, have discussed and briefed a lot on the ecosystem and the things going things going around the world and basically your advice as well. I hope a lot of our listeners will, will take a lot from this particular podcast. And to all our listeners, Do visit that channel, Data Independent on YouTube by Greg. He has published some amazing tools. I believe that It will help you in building some AI AI tools. And thank you, Derek, for for joining us here today. It's been a wonderful talking to you, And we'll be connected for some future podcasts coming soon. So thank you all. Thank you guys for joining here. Have a great day.

00:30:11 Greg: Bye. Awesome. Thank you very much for the time today.

00:30:19 Saurabh: We'll see you