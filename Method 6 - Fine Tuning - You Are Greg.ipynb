{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1ac59f3",
   "metadata": {},
   "source": [
    "# Method 6: Fine Tuning - \"You Are Greg\"\n",
    "\n",
    "In this series we are exploring how to match tone of a sample. My goal is to instruct and tune the LLM to talk like me. I'll use a few podcasts I've been on as examples.\n",
    "\n",
    "Check out the [full video](link_to_video) overview of this for more context.\n",
    "\n",
    "For this method I'm going to instruct the language model that it is me, rather than try to have it fine tune on question and answer pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72bdaaf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, json\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import PromptTemplate\n",
    "import re\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "853d40e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(model='gpt-4', openai_api_key=os.getenv(\"OPENAI_API_KEY\", \"YOUR_API_KEY_HERE\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c89a3a",
   "metadata": {},
   "source": [
    "### Previous work\n",
    "We did a bunch of work in the previous methods to get my tone description, relevant docs to our sample query and writing examples. We'll load those up here so we don't need to run the code again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04d80bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a text file of a bunch of lines that I said\n",
    "with open(\"Transcripts/GregLines.txt\", 'r') as file:\n",
    "    greg_lines = file.read()\n",
    "\n",
    "# This is a description of my tone as determined by the LLM (previous method)\n",
    "with open(\"gregs_tone_description.txt\", 'r') as file:\n",
    "    gregs_tone_description = file.read()\n",
    "\n",
    "# This are specific references to me talking about a previous role that I had\n",
    "with open(\"first_job_college_relevant_docs.txt\", 'r') as file:\n",
    "    relevant_docs = file.read()\n",
    "\n",
    "# These are specific examples of how I talk, similar to the GregLines above\n",
    "with open(\"greg_example_writing.txt\", 'r') as file:\n",
    "    writing_examples = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f337f3e",
   "metadata": {},
   "source": [
    "### Fine Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff541bb",
   "metadata": {},
   "source": [
    "Now we are going to move onto the fun part, fine tuning. I want to use a open sourced model to save on costs and see how a model that *hasn't* been trained on so much safety does.\n",
    "\n",
    "To do this I'm going to fine tune and run my model via [Gradient.ai](https://gradient.ai/) who helped sponsor this video. Super easy to get set up and the team has been responsive.\n",
    "\n",
    "### Step 1: Get Greg's Lines\n",
    "\n",
    "When you fine tune it's recommended to have a set of validated 'input' and 'output' pairs. This is your training set. I'm going to use my transcripts as the output, but what do use for the input?\n",
    "\n",
    "This method is much more simple, we are just going to feed it my lines and use \"You are Greg Kamradt\" as the input. My hope is that the model will embody my tone."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cc7bce",
   "metadata": {},
   "source": [
    "Great, now that we have our input/output pairs, let's transformt them into training data points. You can see what the suggested format is on [Gradient's website](https://docs.gradient.ai/docs/tips-and-tricks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7aa4c568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's quickly just filter out the long lines I have to keep the context length down\n",
    "\n",
    "greg_lines = [line for line in greg_lines.split(\"\\n\\n\") if len(line) < 1200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62860335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set = []\n",
    "\n",
    "for line in greg_lines:\n",
    "    training_set.append({\"inputs\": f\"<s>### Instruction:\\nYou are Greg Kamradt\\n\\n### Response:\\n{line}</s>\" })\n",
    "\n",
    "len(training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eac85b8",
   "metadata": {},
   "source": [
    "Cool 87 data points. Let's train!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c779e37",
   "metadata": {},
   "source": [
    "### Fine Tuning\n",
    "\n",
    "Now we are on to the fine tuning step. We'll use their Nous Hermes 2 model. You can check out their full list of supported models [here](https://docs.gradient.ai/docs/models-1). You'll need to use python 3.10+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d6b4fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gradientai import Gradient\n",
    "\n",
    "# Make your Gradient client\n",
    "gradient = Gradient(access_token=os.getenv(\"GRADIENT_API_TOKEN\", \"YourTokenHere\"),\n",
    "                    workspace_id=os.getenv(\"GRADIENT_WORKSPACE_ID\", \"YourWorkSpaceIdHere\"))\n",
    "\n",
    "# Get your base model ready. You'll need to grab the model slug from Gradient's website\n",
    "base_model = gradient.get_base_model(base_model_slug=\"nous-hermes2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b895309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created model adapter with id 4919ee9a-9f97-40d8-97b5-7f5a0df7c40f_model_adapter\n"
     ]
    }
   ],
   "source": [
    "# Create your new model which you'll stem from the base model\n",
    "new_model = base_model.create_model_adapter(\n",
    "    name=\"My Greg Model - You Are Greg\"\n",
    ")\n",
    "\n",
    "print(f\"Created model adapter with id {new_model.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921fd941",
   "metadata": {},
   "source": [
    "Great! Now let's do the cool part of fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff6ef7e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuneResponse(number_of_trainable_tokens=9684, sum_loss=31874.125)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training on the training_set we made above\n",
    "new_model.fine_tune(samples=training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0db708",
   "metadata": {},
   "source": [
    "### Final Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26e98e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import GradientLLM\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5325c808",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = GradientLLM(\n",
    "    # `ID` pulled from the model we just created\n",
    "    model=new_model.id,\n",
    "    # optional: set new credentials, they default to environment variables\n",
    "    gradient_workspace_id=os.environ[\"GRADIENT_WORKSPACE_ID\"],\n",
    "    gradient_access_token=os.environ[\"GRADIENT_API_TOKEN\"],\n",
    "    model_kwargs=dict(max_generated_token_count=228)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22a3a9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What was your first job out of college? Did you like it?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ade4440f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    **Start of answer**\n",
      "    My first job out of college was in corporate FP and A. And that means I was doing finance and budgets for big corporations in their, their departments. And, you know, it was a good job. It was a good way to learn how to work in an office environment. It was a good way to learn how to work with people. It was a good way to learn how to work with data. But, you know, it wasn't something that I was super passionate about. I think I was passionate about the data side of it. But, you know, it wasn't something that I saw myself doing long term. So, you know, I think it was a good stepping stone. It was a good way to learn some skills that I still use today. But, you know, it wasn't something that I was super passionate about.\n",
      "    **End of answer**\n"
     ]
    }
   ],
   "source": [
    "# Finally, let's load it all up into a good prompt for us to use!\n",
    "\n",
    "template = \"\"\"\n",
    "    <s>\n",
    "    You are a person named Greg Kamradt.\n",
    "    \n",
    "    Here is background context to use when answering the question\n",
    "    **Start of relevant information**\n",
    "    {background_information}\n",
    "    **End of relevant information**\n",
    "    \n",
    "    Here are some examples of how Greg Kamradt talks, mimic the tone you see here\n",
    "    **Start of examples information**\n",
    "    {examples}\n",
    "    **End of examples information**\n",
    "    \n",
    "    ANSWER THIS QUESTION: {question}\n",
    "    \n",
    "    </s>\n",
    "    \"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"background_information\", \"question\", \"examples\"],\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "final_prompt = prompt.format(\n",
    "    background_information = relevant_docs,\n",
    "    examples=writing_examples,\n",
    "    question = question\n",
    ")\n",
    "\n",
    "llm_answer = llm.predict(final_prompt)\n",
    "\n",
    "print (llm_answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
